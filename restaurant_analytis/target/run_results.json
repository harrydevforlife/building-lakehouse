{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v4.json", "dbt_version": "1.5.2", "generated_at": "2023-07-02T19:06:37.008681Z", "invocation_id": "95f54106-0a24-4a8c-a035-1b1bda142a3d", "env": {}}, "results": [{"status": "error", "timing": [], "thread_id": "Thread-1", "execution_time": 0.9504199028015137, "adapter_response": {}, "message": "Runtime Error in model dim_restaurant (models/silver/transform/dim_restaurant.sql)\n  Database Error\n    org.apache.hive.service.cli.HiveSQLException: Error running query: org.apache.spark.sql.AnalysisException: Table or view not found: bronze.restaurant; line 20 pos 9;\n    'CreateViewCommand `dev_silver`.`dim_restaurant`, WITH restaurant_raw AS (\n        SELECT\n            sr.business_id as restaurant_id,\n            sr.name as restaurant_name,\n            sr.categories as categories,\n            sr.city as city,\n            sr.address as address,\n            sr.is_open as is_open,\n            sr.latitude as latitude,\n            sr.longitude as longitude,\n            sr.postal_code as postal_code,\n            sr.review_count as review_count,\n            sr.stars as stars,\n            sr.state as state,\n            sr.hours as hours\n        FROM bronze.restaurant sr\n    )\n    SELECT * FROM restaurant_raw, false, true, PersistedView, false\n    +- 'Project [*]\n       +- 'SubqueryAlias restaurant_raw\n          +- 'Project ['sr.business_id AS restaurant_id#129, 'sr.name AS restaurant_name#130, 'sr.categories AS categories#131, 'sr.city AS city#132, 'sr.address AS address#133, 'sr.is_open AS is_open#134, 'sr.latitude AS latitude#135, 'sr.longitude AS longitude#136, 'sr.postal_code AS postal_code#137, 'sr.review_count AS review_count#138, 'sr.stars AS stars#139, 'sr.state AS state#140, 'sr.hours AS hours#141]\n             +- 'SubqueryAlias sr\n                +- 'UnresolvedRelation [bronze, restaurant], [], false\n    \n    \tat org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:43)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:325)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:230)\n    \tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:79)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties$(SparkOperation.scala:63)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:43)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:230)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:225)\n    \tat java.base/java.security.AccessController.doPrivileged(AccessController.java:712)\n    \tat java.base/javax.security.auth.Subject.doAs(Subject.java:439)\n    \tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:239)\n    \tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n    \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n    \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n    \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n    \tat java.base/java.lang.Thread.run(Thread.java:833)\n    Caused by: org.apache.spark.sql.AnalysisException: Table or view not found: bronze.restaurant; line 20 pos 9;\n    'CreateViewCommand `dev_silver`.`dim_restaurant`, WITH restaurant_raw AS (\n        SELECT\n            sr.business_id as restaurant_id,\n            sr.name as restaurant_name,\n            sr.categories as categories,\n            sr.city as city,\n            sr.address as address,\n            sr.is_open as is_open,\n            sr.latitude as latitude,\n            sr.longitude as longitude,\n            sr.postal_code as postal_code,\n            sr.review_count as review_count,\n            sr.stars as stars,\n            sr.state as state,\n            sr.hours as hours\n        FROM bronze.restaurant sr\n    )\n    SELECT * FROM restaurant_raw, false, true, PersistedView, false\n    +- 'Project [*]\n       +- 'SubqueryAlias restaurant_raw\n          +- 'Project ['sr.business_id AS restaurant_id#129, 'sr.name AS restaurant_name#130, 'sr.categories AS categories#131, 'sr.city AS city#132, 'sr.address AS address#133, 'sr.is_open AS is_open#134, 'sr.latitude AS latitude#135, 'sr.longitude AS longitude#136, 'sr.postal_code AS postal_code#137, 'sr.review_count AS review_count#138, 'sr.stars AS stars#139, 'sr.state AS state#140, 'sr.hours AS hours#141]\n             +- 'SubqueryAlias sr\n                +- 'UnresolvedRelation [bronze, restaurant], [], false\n    \n    \tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n    \tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:131)\n    \tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:102)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:367)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n    \tat scala.collection.Iterator.foreach(Iterator.scala:943)\n    \tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n    \tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n    \tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n    \tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n    \tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n    \tat scala.collection.Iterator.foreach(Iterator.scala:943)\n    \tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n    \tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n    \tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n    \tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n    \tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n    \tat scala.collection.Iterator.foreach(Iterator.scala:943)\n    \tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n    \tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n    \tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n    \tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n    \tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n    \tat scala.collection.Iterator.foreach(Iterator.scala:943)\n    \tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n    \tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n    \tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n    \tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n    \tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n    \tat scala.collection.immutable.List.foreach(List.scala:431)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:102)\n    \tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:97)\n    \tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:188)\n    \tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:214)\n    \tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n    \tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:211)\n    \tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:76)\n    \tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\n    \tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:185)\n    \tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\n    \tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:185)\n    \tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n    \tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:184)\n    \tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:76)\n    \tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n    \tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n    \tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n    \tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n    \tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n    \tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:622)\n    \tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n    \tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:617)\n    \tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:651)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:291)\n    \t... 16 more\n    ", "failures": null, "unique_id": "model.restaurant_analytis.dim_restaurant"}, {"status": "error", "timing": [], "thread_id": "Thread-1", "execution_time": 0.3491334915161133, "adapter_response": {}, "message": "Runtime Error in model dim_user (models/silver/transform/dim_user.sql)\n  Database Error\n    org.apache.hive.service.cli.HiveSQLException: Error running query: org.apache.spark.sql.AnalysisException: Table or view not found: bronze.user; line 26 pos 9;\n    'CreateViewCommand `dev_silver`.`dim_user`, WITH user_raw AS (\n        SELECT \n            us.user_id as user_id,\n            us.name as user_name,\n            us.average_stars as average_stars,\n            us.review_count as review_count,\n            us.funny as funny,\n            us.cool as cool,\n            us.fans as fans,\n            us.friends as friends,\n            us.compliment_cool as compliment_cool,\n            us.compliment_cute as compliment_cute,\n            us.compliment_funny as compliment_funny,\n            us.compliment_hot as compliment_hot,\n            us.compliment_list as compliment_list,\n            us.compliment_more as compliment_more,\n            us.compliment_note as compliment_note,\n            us.compliment_photos as compliment_photos,\n            us.compliment_plain as compliment_plain, \n            us.compliment_profile as compliment_profile,\n            us.compliment_writer as compliment_writer\n        FROM bronze.user us\n    )\n    \n    SELECT * FROM user_raw, false, true, PersistedView, false\n    +- 'Project [*]\n       +- 'SubqueryAlias user_raw\n          +- 'Project ['us.user_id AS user_id#221, 'us.name AS user_name#222, 'us.average_stars AS average_stars#223, 'us.review_count AS review_count#224, 'us.funny AS funny#225, 'us.cool AS cool#226, 'us.fans AS fans#227, 'us.friends AS friends#228, 'us.compliment_cool AS compliment_cool#229, 'us.compliment_cute AS compliment_cute#230, 'us.compliment_funny AS compliment_funny#231, 'us.compliment_hot AS compliment_hot#232, 'us.compliment_list AS compliment_list#233, 'us.compliment_more AS compliment_more#234, 'us.compliment_note AS compliment_note#235, 'us.compliment_photos AS compliment_photos#236, 'us.compliment_plain AS compliment_plain#237, 'us.compliment_profile AS compliment_profile#238, 'us.compliment_writer AS compliment_writer#239]\n             +- 'SubqueryAlias us\n                +- 'UnresolvedRelation [bronze, user], [], false\n    \n    \tat org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:43)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:325)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:230)\n    \tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:79)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties$(SparkOperation.scala:63)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:43)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:230)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:225)\n    \tat java.base/java.security.AccessController.doPrivileged(AccessController.java:712)\n    \tat java.base/javax.security.auth.Subject.doAs(Subject.java:439)\n    \tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:239)\n    \tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n    \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n    \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n    \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n    \tat java.base/java.lang.Thread.run(Thread.java:833)\n    Caused by: org.apache.spark.sql.AnalysisException: Table or view not found: bronze.user; line 26 pos 9;\n    'CreateViewCommand `dev_silver`.`dim_user`, WITH user_raw AS (\n        SELECT \n            us.user_id as user_id,\n            us.name as user_name,\n            us.average_stars as average_stars,\n            us.review_count as review_count,\n            us.funny as funny,\n            us.cool as cool,\n            us.fans as fans,\n            us.friends as friends,\n            us.compliment_cool as compliment_cool,\n            us.compliment_cute as compliment_cute,\n            us.compliment_funny as compliment_funny,\n            us.compliment_hot as compliment_hot,\n            us.compliment_list as compliment_list,\n            us.compliment_more as compliment_more,\n            us.compliment_note as compliment_note,\n            us.compliment_photos as compliment_photos,\n            us.compliment_plain as compliment_plain, \n            us.compliment_profile as compliment_profile,\n            us.compliment_writer as compliment_writer\n        FROM bronze.user us\n    )\n    \n    SELECT * FROM user_raw, false, true, PersistedView, false\n    +- 'Project [*]\n       +- 'SubqueryAlias user_raw\n          +- 'Project ['us.user_id AS user_id#221, 'us.name AS user_name#222, 'us.average_stars AS average_stars#223, 'us.review_count AS review_count#224, 'us.funny AS funny#225, 'us.cool AS cool#226, 'us.fans AS fans#227, 'us.friends AS friends#228, 'us.compliment_cool AS compliment_cool#229, 'us.compliment_cute AS compliment_cute#230, 'us.compliment_funny AS compliment_funny#231, 'us.compliment_hot AS compliment_hot#232, 'us.compliment_list AS compliment_list#233, 'us.compliment_more AS compliment_more#234, 'us.compliment_note AS compliment_note#235, 'us.compliment_photos AS compliment_photos#236, 'us.compliment_plain AS compliment_plain#237, 'us.compliment_profile AS compliment_profile#238, 'us.compliment_writer AS compliment_writer#239]\n             +- 'SubqueryAlias us\n                +- 'UnresolvedRelation [bronze, user], [], false\n    \n    \tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n    \tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:131)\n    \tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:102)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:367)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n    \tat scala.collection.Iterator.foreach(Iterator.scala:943)\n    \tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n    \tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n    \tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n    \tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n    \tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n    \tat scala.collection.Iterator.foreach(Iterator.scala:943)\n    \tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n    \tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n    \tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n    \tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n    \tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n    \tat scala.collection.Iterator.foreach(Iterator.scala:943)\n    \tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n    \tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n    \tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n    \tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n    \tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n    \tat scala.collection.Iterator.foreach(Iterator.scala:943)\n    \tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n    \tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n    \tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n    \tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n    \tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n    \tat scala.collection.immutable.List.foreach(List.scala:431)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:102)\n    \tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:97)\n    \tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:188)\n    \tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:214)\n    \tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n    \tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:211)\n    \tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:76)\n    \tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\n    \tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:185)\n    \tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\n    \tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:185)\n    \tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n    \tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:184)\n    \tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:76)\n    \tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n    \tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n    \tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n    \tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n    \tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n    \tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:622)\n    \tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n    \tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:617)\n    \tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:651)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:291)\n    \t... 16 more\n    ", "failures": null, "unique_id": "model.restaurant_analytis.dim_user"}, {"status": "error", "timing": [], "thread_id": "Thread-1", "execution_time": 0.4084441661834717, "adapter_response": {}, "message": "Runtime Error in model fact_review (models/silver/transform/fact_review.sql)\n  Database Error\n    org.apache.hive.service.cli.HiveSQLException: Error running query: org.apache.spark.sql.AnalysisException: Table or view not found: bronze.review; line 16 pos 9;\n    'CreateViewCommand `dev_silver`.`fact_review`, WITH review_raw AS (\n        SELECT\n            rr.review_id as review_id,\n            rr.business_id as restaurant_id,\n            rr.user_id as user_id,\n            rr.stars as stars,\n            rr.cool as cool,\n            rr.funny as funny,\n            rr.useful as useful,\n            date_format(to_timestamp(rr.date, 'yyyy-MM-dd HH:mm:ss'), 'yyyy-MM-dd HH:mm:ss') as review_date,\n            rr.text as review_description\n        FROM bronze.review rr\n    )\n    SELECT * FROM review_raw, false, true, PersistedView, false\n    +- 'Project [*]\n       +- 'SubqueryAlias review_raw\n          +- 'Project ['rr.review_id AS review_id#319, 'rr.business_id AS restaurant_id#320, 'rr.user_id AS user_id#321, 'rr.stars AS stars#322, 'rr.cool AS cool#323, 'rr.funny AS funny#324, 'rr.useful AS useful#325, 'date_format('to_timestamp('rr.date, yyyy-MM-dd HH:mm:ss), yyyy-MM-dd HH:mm:ss) AS review_date#326, 'rr.text AS review_description#327]\n             +- 'SubqueryAlias rr\n                +- 'UnresolvedRelation [bronze, review], [], false\n    \n    \tat org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:43)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:325)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:230)\n    \tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:79)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties$(SparkOperation.scala:63)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:43)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:230)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:225)\n    \tat java.base/java.security.AccessController.doPrivileged(AccessController.java:712)\n    \tat java.base/javax.security.auth.Subject.doAs(Subject.java:439)\n    \tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:239)\n    \tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n    \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n    \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n    \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n    \tat java.base/java.lang.Thread.run(Thread.java:833)\n    Caused by: org.apache.spark.sql.AnalysisException: Table or view not found: bronze.review; line 16 pos 9;\n    'CreateViewCommand `dev_silver`.`fact_review`, WITH review_raw AS (\n        SELECT\n            rr.review_id as review_id,\n            rr.business_id as restaurant_id,\n            rr.user_id as user_id,\n            rr.stars as stars,\n            rr.cool as cool,\n            rr.funny as funny,\n            rr.useful as useful,\n            date_format(to_timestamp(rr.date, 'yyyy-MM-dd HH:mm:ss'), 'yyyy-MM-dd HH:mm:ss') as review_date,\n            rr.text as review_description\n        FROM bronze.review rr\n    )\n    SELECT * FROM review_raw, false, true, PersistedView, false\n    +- 'Project [*]\n       +- 'SubqueryAlias review_raw\n          +- 'Project ['rr.review_id AS review_id#319, 'rr.business_id AS restaurant_id#320, 'rr.user_id AS user_id#321, 'rr.stars AS stars#322, 'rr.cool AS cool#323, 'rr.funny AS funny#324, 'rr.useful AS useful#325, 'date_format('to_timestamp('rr.date, yyyy-MM-dd HH:mm:ss), yyyy-MM-dd HH:mm:ss) AS review_date#326, 'rr.text AS review_description#327]\n             +- 'SubqueryAlias rr\n                +- 'UnresolvedRelation [bronze, review], [], false\n    \n    \tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n    \tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:131)\n    \tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:102)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:367)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n    \tat scala.collection.Iterator.foreach(Iterator.scala:943)\n    \tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n    \tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n    \tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n    \tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n    \tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n    \tat scala.collection.Iterator.foreach(Iterator.scala:943)\n    \tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n    \tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n    \tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n    \tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n    \tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n    \tat scala.collection.Iterator.foreach(Iterator.scala:943)\n    \tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n    \tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n    \tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n    \tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n    \tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n    \tat scala.collection.Iterator.foreach(Iterator.scala:943)\n    \tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n    \tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n    \tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n    \tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n    \tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n    \tat scala.collection.immutable.List.foreach(List.scala:431)\n    \tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n    \tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:102)\n    \tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:97)\n    \tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:188)\n    \tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:214)\n    \tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n    \tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:211)\n    \tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:76)\n    \tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\n    \tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:185)\n    \tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\n    \tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:185)\n    \tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n    \tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:184)\n    \tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:76)\n    \tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n    \tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n    \tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n    \tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n    \tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n    \tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:622)\n    \tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n    \tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:617)\n    \tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:651)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:291)\n    \t... 16 more\n    ", "failures": null, "unique_id": "model.restaurant_analytis.fact_review"}, {"status": "skipped", "timing": [], "thread_id": "Thread-1", "execution_time": 0.0, "adapter_response": {}, "message": null, "failures": null, "unique_id": "model.restaurant_analytis.analyses_review"}], "elapsed_time": 8.438180685043335, "args": {"enable_legacy_logger": false, "introspect": true, "quiet": false, "write_json": true, "defer": false, "which": "run", "partial_parse": true, "indirect_selection": "eager", "log_level": "info", "select": [], "profiles_dir": "/usr/local/airflow/restaurant_analytis", "use_colors_file": true, "log_path": "/usr/local/airflow/restaurant_analytis/logs", "project_dir": "/usr/local/airflow/restaurant_analytis", "use_colors": true, "cache_selected_only": false, "log_level_file": "debug", "printer_width": 80, "version_check": true, "warn_error_options": {"include": [], "exclude": []}, "print": true, "favor_state": false, "log_format_file": "debug", "macro_debugging": false, "populate_cache": true, "send_anonymous_usage_stats": true, "exclude": [], "vars": {}, "static_parser": true, "log_format": "default", "strict_mode": false}}